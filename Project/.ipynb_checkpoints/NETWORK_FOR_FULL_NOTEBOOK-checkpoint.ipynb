{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "worthy-agenda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import networkx as nx\n",
    "import netwulf as nw\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from scipy import stats\n",
    "from networkx.algorithms import community\n",
    "import community\n",
    "import json\n",
    "  \n",
    "\n",
    "seed = 1337\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-following",
   "metadata": {},
   "source": [
    "# Network\n",
    "This section of the notebook will go through the network analysis of the data. We have used `networkx` to build the networks and `netwulf` to visualise them. The the following sections we will be investigating the full network of all musicians as well as a subset of them based on selected genres. The networks will be studied by calculating different statistics, such as number of nodes, number of links, density, clusterings and more. In addition, we will look at community detection to see how well the different genres manages to partition the networks into communities in comparison to the Louvain algorithm for community detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-birthday",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dirty-diploma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of songs: 25419\n"
     ]
    }
   ],
   "source": [
    "song_data = pd.read_pickle('songData.df')\n",
    "print(f'Number of songs: {len(song_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seventh-capital",
   "metadata": {},
   "source": [
    "Network visualisation config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "massive-attention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the data from the file\n",
    "with open('network_figures/config.txt') as f:\n",
    "    data = f.read()\n",
    "config = json.loads(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-joshua",
   "metadata": {},
   "source": [
    "## Creating the full network\n",
    "Calculate all genres associated to each artist as well as how many songs they have made for each genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "spare-casting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique artists: 7855\n"
     ]
    }
   ],
   "source": [
    "all_artists = set()\n",
    "artist_genres = dict()\n",
    "artist_genres_count = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "for artists, genres in zip(song_data.artists, song_data.genres):\n",
    "    for artist in artists:\n",
    "        all_artists = all_artists.union(set([artist]))\n",
    "        for genre in genres:\n",
    "            artist_genres_count[artist][genre] += 1\n",
    "        if artist in artist_genres.keys():\n",
    "            artist_genres[artist] = artist_genres[artist].union(set(genres))\n",
    "        else:\n",
    "            artist_genres[artist] = set(genres)\n",
    "        \n",
    "\n",
    "all_artists = list(all_artists)\n",
    "print(f'Number of unique artists: {len(all_artists)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-respect",
   "metadata": {},
   "source": [
    "Creating a genre list from which each artist can get their main genre label. In addition, a colour list to colour each node based on their main genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "naked-beads",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_list = ['pop', 'rock', 'rap', 'r&b', 'country', 'soul', \n",
    "              'singer-songwriter', 'pop-rock', 'trap', 'ballad', \n",
    "             'soul pop', 'eighties', 'seventies', 'soundtrack',\n",
    "             'hip-hop', 'funk', 'dance', 'electronic', 'folk', 'cover', \n",
    "             'jazz', 'blues']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "complicated-mason",
   "metadata": {},
   "outputs": [],
   "source": [
    "colour_list = ['#E74C3C', '#9B59B6', '#3498DB', '#1ABC9C', '#27AE60', '#F4D03F', '#E67E22', '#EDB9B9', '#E7E9B9',\n",
    "              '#B9EDE0', '#B9D7ED', '#DCB9ED', '#8F2323', '#8F6A23', '#4F8F23', '#23628F', '#6B238F', '#AED6F1',\n",
    "              '#A3E4D7', '#D4AC0D', '#D7BDE2', '#F5B7B1', '#0A2ADA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "south-watch",
   "metadata": {},
   "outputs": [],
   "source": [
    "colour_dict = {}\n",
    "for colour, genre in zip(colour_list, genre_list+['other']):\n",
    "    colour_dict[genre] = colour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-brown",
   "metadata": {},
   "source": [
    "Calculate number of songs each artist has in the data set as well as how many times they have collaborated with other artists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "undefined-particular",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_count = defaultdict(lambda: 0)\n",
    "artist_colab_count = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "for artists in song_data.artists:\n",
    "    for artist in artists:\n",
    "        artist_count[artist] += 1\n",
    "        for colab in artists:\n",
    "            if colab != artist:\n",
    "                artist_colab_count[artist][colab] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "introductory-salem",
   "metadata": {},
   "source": [
    "### Add nodes\n",
    "Add each artist as a node with three attributes\n",
    "> *genre*: most common genre for that artist within the fixed list 'genre_list'\n",
    "\n",
    "> *size*: number of times the artist has appeared on Billboard's the hot 100 (used to give each node the correct size)\n",
    "\n",
    "> *all_genres*: all genres associated with that artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "legendary-universe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 7855\n"
     ]
    }
   ],
   "source": [
    "G = nx.Graph()\n",
    "for artist in all_artists:\n",
    "    most_occurences = 0\n",
    "    max_key = 'other'\n",
    "    random.shuffle(genre_list)\n",
    "    \n",
    "    for genre in genre_list:\n",
    "        if genre in artist_genres_count[artist]:\n",
    "            if artist_genres_count[artist][genre] > most_occurences:\n",
    "                most_occurences = artist_genres_count[artist][genre]\n",
    "                max_key = genre\n",
    "                \n",
    "    G.add_node(artist, \n",
    "               genre=max_key, \n",
    "               size=artist_count[artist], \n",
    "               all_genres=artist_genres[artist], \n",
    "               group=colour_dict[max_key])\n",
    "    \n",
    "G.number_of_nodes()\n",
    "print(f'Number of nodes: {G.number_of_nodes()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-method",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Add edges\n",
    "Add edges between two artists if they have collaborated on a song and weigh the edge by the number of times they have collaborated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "amber-somerset",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges: 6799\n"
     ]
    }
   ],
   "source": [
    "linked_artists = set()\n",
    "for artists in song_data.artists:\n",
    "    if len(artists) > 1:\n",
    "        for comb in combinations(artists, 2):\n",
    "            if not comb[0] == comb[1]:\n",
    "                linked_artists = linked_artists.union({tuple([comb[0], comb[1], artist_colab_count[comb[0]][comb[1]]])})\n",
    "\n",
    "linked_artists = list(linked_artists)\n",
    "G.add_weighted_edges_from(linked_artists)\n",
    "print(f'Number of edges: {G.number_of_edges()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-bahrain",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "humanitarian-turkish",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomized_graph(graph, N):\n",
    "    g = graph.copy()\n",
    "    swaps = 0\n",
    "    while swaps < N:\n",
    "        uv = random.choice(list(g.edges()))\n",
    "        if uv[0] == uv[1]:\n",
    "            uv = random.choice(list(g.edges()))\n",
    "        xy = random.choice(list(g.edges()))\n",
    "        while uv[1] == xy[0]:\n",
    "            xy = random.choice(list(g.edges()))\n",
    "        if not g.has_edge(uv[0], xy[1]) and not g.has_edge(uv[1], xy[0]):\n",
    "            g.remove_edges_from([uv, xy])\n",
    "            g.add_edges_from([(uv[0], xy[1]), (uv[1], xy[0])])\n",
    "            swaps += 1\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "operating-brazil",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_network_by_genre(G, genre):\n",
    "    genre_nodes = [node for node, data in G.nodes(data=True) if genre in data['all_genres']]\n",
    "    return G.subgraph(genre_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "minus-partition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_partitioning(filtered_graph):\n",
    "    partitioning = []\n",
    "    nc = set(nx.get_node_attributes(filtered_graph, 'group').values())\n",
    "    for i in nc:\n",
    "        nodes = (\n",
    "            node\n",
    "            for node, data\n",
    "            in filtered_graph.nodes(data=True)\n",
    "            if data.get(\"group\") == i\n",
    "        )\n",
    "        partitioning.append(filtered_graph.subgraph(nodes))\n",
    "    return partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "graphic-cornwall",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modularity(graph, partitioning):\n",
    "    M = 0\n",
    "    L = graph.number_of_edges()\n",
    "    for subgraph in partitioning:\n",
    "        Lc = subgraph.number_of_edges()\n",
    "        kc = sum(graph.degree[node] for node in subgraph.nodes())\n",
    "        M += Lc/L - (kc / (2 * L))**2\n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-section",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "The full network has now been created and we are ready to do visualisations and analysis. In the following sections we will be working with the full network and sub-networks for the genres: _pop_, _rap_, _rock_, _R&B_, _country_, _funk_, _folk_ and _blues_. For each of the networks we will be investigating the full network as well versions of the network where singleton nodes with less than 5 songs are removed. \n",
    "\n",
    "# Mangler et godt argument her for hvorfor vi har valgt at fjerne singletons med mindre end 5 sange. \n",
    "\n",
    "### With singletons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_G, _ = nw.visualize(G, config=config, plot_in_cell_below=False)\n",
    "fig, ax = nw.draw_netwulf(network_G)\n",
    "# plt.savefig(\"network_figures/G.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-prototype",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-tulsa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-penny",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-sally",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-appendix",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-arbitration",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-prospect",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-powder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-emergency",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-study",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
