{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fatty-encounter",
   "metadata": {},
   "source": [
    "# 1. Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-newman",
   "metadata": {},
   "source": [
    "### What is your dataset?\n",
    "\n",
    "The dataset we will be analysing is a collection of songs, each with the artists that worked on them, the lyrics, and the release date.\n",
    "\n",
    "The network will be created with each artist as a node and the links will be if the artists have collaborated on a song.\n",
    "\n",
    "The text analysis will be conducted on the lyrics of all the songs gathered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-darkness",
   "metadata": {},
   "source": [
    "### Why did you choose this dataset?\n",
    "\n",
    "Musicians tend to collaborate together, which we thought would make for an interesting network. Furthermore, investigating the different artists language through their song lyrics to find patterns and attributes would be fun."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-person",
   "metadata": {},
   "source": [
    "### What was your goal for the end user's experience?\n",
    "\n",
    "We wanted to provide some insight into how artists collaborate, which genres collaborate more, which artists collaborate more and how the language between genres and artists differs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smaller-finder",
   "metadata": {},
   "source": [
    "## Scraping the data\n",
    "\n",
    "Since song titles on Billboard's 'The Hot 100' have horrible naming schemes, which differs a lot from one song to another, some preprocessing need to take place. An example of this, is the artist *Earth, Wind \\& Fire with The Emotions* which actually denotes *Earth, Wind \\& Fire* featuring *The Emotions*. When searching for songs on the Genius website, the best result achieved when searching for both the song title and artists, as many songs share titles. The problem comes when we search for *Boogie Wonderland* by *Earth, Wind \\& Fire with The Emotions* using the Genius API, since this won't return any song.\n",
    "\n",
    "When searching for songs using the Genius API, we used a sequential searching strategy. This means that we would first search for the song title and full artist name and if that does not yield any results, we first split the artist name at *'feature'*, *'feat.'*, *'ft.'* or *'with'* and then search for the song title and the first partition of the artists name query. If this still doesn't result in any valid song, we remove parentheses from the artist names and replace *'and'* with *'&'*, after which we again search for the song title and artists name. If this fails as well, we try splitting the modified artist names at *'&'* and *','* and search again. If none of these steps result in a valid song, we simply search for the song title and hope for the best.\n",
    "\n",
    "Immediately after loading a song, we make sure it is actually a song. To do this, we filter out songs with specific genres/tags, as Genius also house texts which are not song lyrics. We therefore used the following list of bad genres to avoid those; `['track\\\\s?list', 'album art(work)?', 'liner notes', 'booklet', 'credits', 'interview', 'skit', 'instrumental', 'setlist', 'non-music', 'literature']`.\n",
    "\n",
    "The last step before all the raw data was gathered, was to separate all artists for each song. This was done using regex to find and split artists at *','*, *'and'*, *'featuring'* and so on. This results in the artists *Megan Thee Stallion & Dua Lipa* for the song *Sweetest Pie* to be changed to `[Megan Thee Stallion, Dua Lipa]` and the artists *Lil Durk Featuring Gunna* for the song *What Happened To Virgil* to be changed to `[Lil Durk, Gunna]`. However, a negative side effect of this processing is, that artists like the previously mentioned *Earth, Wind & Fire* was changed to `[Earth, Wind, Fire]`. This was a necessary part of the preprocessing and these kinds of artists were regrouped later in the data cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sapphire-scale",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lyricsgenius import Genius\n",
    "import re\n",
    "import billboard\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "from requests.exceptions import Timeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-german",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = billboard.ChartData('hot-100', date=\"1960-01-04\", fetch=True, timeout=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-assistant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty dataframe\n",
    "columns = ['title', 'artist', 'rank', 'date', 'weeks']\n",
    "songInfo = pd.DataFrame(None, columns=columns)\n",
    "\n",
    "start = datetime.strptime('Jan 4 1960', '%b %d %Y')\n",
    "end = datetime.now()\n",
    "#end = datetime.strptime('Jan 4 1961', '%b %d %Y')\n",
    "\n",
    "# Run the code below to scrape BillBoard 100\n",
    "\n",
    "# outer_bar = tqdm(range(len(list(rrule.rrule(rrule.WEEKLY, dtstart=start, until=end)))), desc=f\"Progress\", position=0, leave=True)\n",
    "# for dt in rrule.rrule(rrule.WEEKLY, dtstart=start, until=end):\n",
    "#     outer_bar.update(1)\n",
    "#     chart = billboard.ChartData('hot-100', date=dt.strftime(\"%Y-%m-%d\"), fetch=True, timeout=25)\n",
    "#     for song in chart:\n",
    "#         if dt == start:\n",
    "#             songInfo.loc[len(songInfo)] = [song.title, song.artist, song.rank, dt.strftime(\"%Y-%m-%d\"), song.weeks]\n",
    "#         else:\n",
    "#             if song.isNew:\n",
    "#                 songInfo.loc[len(songInfo)] = [song.title, song.artist, song.rank, dt.strftime(\"%Y-%m-%d\"), song.weeks]\n",
    "# #             else:\n",
    "# #                 index = (songInfo['title'] == song.title) & (songInfo['artist'] == song.artist)\n",
    "# #                 index = np.argmax(index)\n",
    "# #                 #row = (songInfo['title'] == song.title) & (songInfo['artist'] == song.artist)\n",
    "# #                 if len(songInfo.iloc[index]) == 0:\n",
    "# #                     songInfo.loc[len(songInfo)] = [song.title, song.artist, song.rank, dt.strftime(\"%Y-%m-%d\"), song.weeks]\n",
    "# #                 elif song.rank > songInfo.loc[index, \"rank\"]:\n",
    "# #                     songInfo.loc[index, \"rank\"] = song.rank\n",
    "# #                     songInfo.loc[index, \"date\"] = dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# songInfo.to_csv(\"songInfo.csv\")\n",
    "# songInfo.to_csv(\"songInfo_noIndex.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-joint",
   "metadata": {},
   "outputs": [],
   "source": [
    "songInfo = pd.read_csv('songInfo.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-compiler",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = 'UNXh1BykDmagMbxVjcAeMXiwDhnkmgsDC3a2AM2YWRKzLhLDpxsRJzfdvXP2cXRZ'\n",
    "genius = Genius(token, timeout=20, remove_section_headers=True, verbose=False, skip_non_songs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-senate",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_expressions = ['feature', 'feat.', 'ft.', ' with ', '(with ']\n",
    "extra_expressions = [' and ', ' & ', ',']\n",
    "\n",
    "def find_artist(name):\n",
    "    artist = genius.search_artist(name, max_songs=0)\n",
    "    if artist is not None:\n",
    "        return artist\n",
    "\n",
    "    name = name.lower()\n",
    "    og_name = name\n",
    "    for fe in feature_expressions:\n",
    "        if fe in name:\n",
    "            name = name.split(fe)[0]\n",
    "            break\n",
    "\n",
    "    if name != og_name:\n",
    "        artist = genius.search_artist(name, max_songs=0)\n",
    "        if artist is not None:\n",
    "            return artist\n",
    "\n",
    "\n",
    "    name = name.replace('(', '')\n",
    "    name = name.replace(')', '')\n",
    "\n",
    "    artist = genius.search_artist(name.replace(' and ', ' & '), max_songs=0)\n",
    "    if artist is not None:\n",
    "        return artist\n",
    "\n",
    "    og_name = name\n",
    "    for ee in extra_expressions:\n",
    "        if ee in name:\n",
    "            name = name.split(ee)[0]\n",
    "    if name != og_name:\n",
    "        artist = genius.search_artist(name, max_songs=0)\n",
    "    return artist\n",
    "\n",
    "def find_song(artist, title):\n",
    "    song = genius.search_song(title, artist)\n",
    "    if song is not None:\n",
    "        return song\n",
    "\n",
    "    artist = artist.lower()\n",
    "    og_artist = artist\n",
    "    for fe in feature_expressions:\n",
    "        if fe in artist:\n",
    "            artist = artist.split(fe)[0]\n",
    "            break\n",
    "\n",
    "    if artist != og_artist:\n",
    "        song = genius.search_song(title, artist.title())\n",
    "        if song is not None:\n",
    "            return song\n",
    "\n",
    "    artist = artist.replace('(', '')\n",
    "    artist = artist.replace(')', '')\n",
    "\n",
    "    artist_and = artist.replace(' and ', ' & ')\n",
    "    if artist != artist_and:\n",
    "        song = genius.search_song(title, artist_and.title())\n",
    "        if song is not None:\n",
    "            return song\n",
    "\n",
    "    og_artist = artist\n",
    "    for ee in extra_expressions:\n",
    "        if ee in artist:\n",
    "            artist = artist.split(ee)[0]\n",
    "    if artist != og_artist:\n",
    "        song = genius.search_song(title, artist.title())\n",
    "    if song is not None:\n",
    "        return song\n",
    "\n",
    "    song = genius.search_song(title)\n",
    "    return song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-emergency",
   "metadata": {},
   "outputs": [],
   "source": [
    "def artist_to_list(name_segment):\n",
    "    if ' & ' in name_segment:\n",
    "        artist_list = name_segment.split(' & ')\n",
    "        if ', ' in artist_list[0]:\n",
    "            artist_list = artist_list[0].split(', ') + [artist_list[1]]\n",
    "        return artist_list\n",
    "    return [name_segment]\n",
    "\n",
    "def process_artist_names(artist_names):\n",
    "    ft_code = '(?<=\\(Ft\\. )(.*?)(?=\\))'\n",
    "    main_code = '(.*?) \\('\n",
    "    features = re.findall(ft_code, artist_names)\n",
    "    if not features:\n",
    "        main_artists = artist_names\n",
    "        all_artists = artist_to_list(main_artists)\n",
    "    else:\n",
    "        all_artists = artist_to_list(features[0])\n",
    "        main_artists = re.findall(main_code, artist_names)\n",
    "        all_artists += artist_to_list(main_artists[0])\n",
    "\n",
    "    return all_artists\n",
    "\n",
    "def convert_date(date):\n",
    "    try:\n",
    "        if len(date) < 5:\n",
    "            conv_date = datetime.strptime(date, '%Y')\n",
    "            conv_date_str = datetime.strftime(conv_date, '%Y')\n",
    "        else:\n",
    "            conv_date = datetime.strptime(date, '%B %d, %Y')\n",
    "            conv_date_str = datetime.strftime(conv_date, '%Y-%m-%d')\n",
    "    except:\n",
    "        return date\n",
    "    return conv_date_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-universe",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['released', 'artists', 'lyrics', 'genres', 'title']\n",
    "genius_df = pd.DataFrame(None, columns=columns)\n",
    "\n",
    "bad_genres = {'track\\\\s?list', 'album art(work)?', 'liner notes', 'booklet', 'credits', 'interview', 'skit', 'instrumental', 'setlist', 'non-music', 'literature'}\n",
    "\n",
    "John = '8======D'\n",
    "flipped_John = 'C======8'\n",
    "\n",
    "N = len(songInfo)\n",
    "now = time.time()\n",
    "\n",
    "successes = 0\n",
    "\n",
    "last_checkpoint = 29100\n",
    "step = 28\n",
    "\n",
    "for i in range(last_checkpoint, N):\n",
    "    print(f'Succes rate: {successes} / {i-last_checkpoint}')\n",
    "    print('='*50)\n",
    "    while True:\n",
    "        try:\n",
    "            song = find_song(songInfo.artist[i], songInfo.title[i])\n",
    "            break\n",
    "        except:\n",
    "            print('Failed to find song... Trying again.')\n",
    "            pass\n",
    "    if song is None:\n",
    "        print('Failed at song:', songInfo.artist[i], 'with title:', songInfo.title[i], '\\nDue to no song found')\n",
    "        continue\n",
    "\n",
    "    raw_lyrics = song.lyrics\n",
    "    if not raw_lyrics:\n",
    "        print('Failed at song:', songInfo.artist[i], 'with title:', songInfo.title[i], '\\nDue to empty lyric')\n",
    "        continue\n",
    "\n",
    "    lyrics, genres_and_release_date = raw_lyrics.split(John)\n",
    "    raw_genres, release_date = genres_and_release_date.split(flipped_John)\n",
    "    genres = raw_genres.split('_')\n",
    "    bad_genre = None\n",
    "    for genre in genres:\n",
    "        if genre in bad_genres:\n",
    "            bad_genre = genre\n",
    "            break\n",
    "    if bad_genre is not None:\n",
    "        print('Failed at song:', songInfo.artist[i], 'with title:', songInfo.title[i], f'\\nDue to bad genre: {bad_genre}')\n",
    "        continue\n",
    "\n",
    "    if release_date == 'Unknown':\n",
    "        release_date = songInfo.date[i]\n",
    "    else:\n",
    "        release_date = convert_date(release_date)\n",
    "    sd = song.to_dict()\n",
    "    title = sd['title']\n",
    "\n",
    "    artists = process_artist_names(sd['artist_names'])\n",
    "\n",
    "    genius_df.loc[i] = [release_date, artists, lyrics, genres, title]\n",
    "\n",
    "    if not (i+1) % step:\n",
    "        print('SAVING CHECKPOINT!')\n",
    "        genius_df.to_csv(f'songData{last_checkpoint}_{i}.csv')\n",
    "        try:\n",
    "            os.remove(f'songData{last_checkpoint}_{i-step}.csv')\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "\n",
    "    successes += 1\n",
    "\n",
    "    now_now = time.time()\n",
    "    print(f'Song number {i+1} of {N}, time spent on song: {now_now - now:.2f} seconds')\n",
    "    now = now_now\n",
    "    # print(f'Artists: {songInfo.artist[i]:>10}, {\" \".join(artists):>20}')\n",
    "    print(f'Artists: {songInfo.artist[i]:>20}')\n",
    "    print(f'{\", \".join(artists):>29}')\n",
    "    print(f'Title: {songInfo.title[i][:20]:>32}')\n",
    "    print(f'{title[:20]:>39}')\n",
    "    print(f'Date: {songInfo.date[i]:>20}')\n",
    "    print(f'{release_date:>26}')\n",
    "    print(f'Genres: {\", \".join(genres):>20}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-violation",
   "metadata": {},
   "source": [
    "This way, when collecting data for each song through the modified LyricsGenius API, we would retrieve five attributes: date of release, artists who collaborated on the song, lyrics, genres and the song title. The data looks as follows:\n",
    "\n",
    "|   released |          artists |                                             lyrics |           genres |                          title |\n",
    "|-----------:|-----------------:|---------------------------------------------------:|-----------------:|-------------------------------:|\n",
    "|       1957 |  [marty robbins] |  El Paso Lyrics\\nOut in the West Texas town of ... |        [country] |                        El Paso |\n",
    "| 1960-01-04 | [frankie avalon] | Why Lyrics I'll never let you go\\nWhy? Because ... |            [pop] |                            Why |\n",
    "|       1959 | [johnny preston] |  Running Bear LyricsOn the bank of the river\\nS... |            [pop] |                   Running Bear |\n",
    "| 1960-01-04 |  [freddy cannon] | Way Down Yonder in New Orleans LyricsWell, way ... |            [pop] | Way Down Yonder in New Orleans |\n",
    "| 1960-01-04 |   [guy mitchell] |  Heartaches by the Number Lyrics\\nHeartaches by... | [country, cover] |       Heartaches by the Number |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-attitude",
   "metadata": {},
   "source": [
    "# 2. Basic stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-serial",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "At this point we had all the raw data, but it was apparent that in spite of our efforts during the data gathering, a lot of cleaning still had to be done.\n",
    "\n",
    "#### Unwanted characters and non-english songs\n",
    "First of all, unwanted unicodes like *\\u200b*, *\\u200c* and *\\u200e*, which had slipped in when the data was loaded, was removed from artists, genres and the lyrics. Next up, duplicates were removed and songs which were not in english were removed by doing a language detection with the Python module `langdetect`.\n",
    "\n",
    "As can be seen in the table above, each of the songs' lyric's begins with the title of the song and *'Lyrics'*. This was also removed, as it wasn't part of the actually lyrics, but rather an artifact from gathering the song info using the Genius API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-technique",
   "metadata": {},
   "outputs": [],
   "source": [
    "songInfo = pd.read_csv('songInfo.csv', index_col=0)\n",
    "songData = pd.read_csv('songData.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-accessory",
   "metadata": {},
   "outputs": [],
   "source": [
    "John = '8======D'\n",
    "flipped_John = 'C======8'\n",
    "\n",
    "def convert_date(date):\n",
    "    try:\n",
    "        if len(date) < 5:\n",
    "            conv_date = datetime.strptime(date, '%Y')\n",
    "            conv_date_str = datetime.strftime(conv_date, '%Y')\n",
    "        else:\n",
    "            conv_date = datetime.strptime(date, '%B %d, %Y')\n",
    "            conv_date_str = datetime.strftime(conv_date, '%Y-%m-%d')\n",
    "    except:\n",
    "        return date\n",
    "    return conv_date_str\n",
    "\n",
    "def artist_to_list(name_segment):\n",
    "    if ' & ' in name_segment:\n",
    "        artist_list = name_segment.split(' & ')\n",
    "        if ', ' in artist_list[0]:\n",
    "            artist_list = artist_list[0].split(', ') + [artist_list[1]]\n",
    "        return artist_list\n",
    "    return [name_segment]\n",
    "\n",
    "def process_artist_names(artist_names):\n",
    "    ft_code = '(?<=\\(Ft\\. )(.*?)(?=\\))'\n",
    "    main_code = '(.*?) \\('\n",
    "    features = re.findall(ft_code, artist_names)\n",
    "    if not features:\n",
    "        main_artists = artist_names\n",
    "        all_artists = artist_to_list(main_artists)\n",
    "    else:\n",
    "        all_artists = artist_to_list(features[0])\n",
    "        main_artists = re.findall(main_code, artist_names)\n",
    "        all_artists += artist_to_list(main_artists[0])\n",
    "\n",
    "    return all_artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-conclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = 'UNXh1BykDmagMbxVjcAeMXiwDhnkmgsDC3a2AM2YWRKzLhLDpxsRJzfdvXP2cXRZ'\n",
    "genius = Genius(token, timeout=20, remove_section_headers=True, verbose=False, skip_non_songs=False)\n",
    "for val, tit, art in zip(songData.index.values, songData.title, songData.artists):\n",
    "    if 'Genius' in ''.join(art):\n",
    "        print(val, art, tit)\n",
    "        try:\n",
    "            artist, rest = tit.split(' â€” ')\n",
    "        except:\n",
    "            #songData = songData.drop(val)\n",
    "            continue\n",
    "        \n",
    "        print('='*50)\n",
    "        print(f'artist: {artist}')\n",
    "        print(f'title: {rest}')\n",
    "        \n",
    "        title = rest.split('ft.')[0]\n",
    "        \n",
    "        code = '(.*?) (?=\\(.+ .+\\))'\n",
    "        cut_title = re.findall(code, title)\n",
    "        if cut_title:\n",
    "            title = cut_title[0]\n",
    "            \n",
    "        artist = artist.split(' & ')[0]\n",
    "        \n",
    "        song = genius.search_song(title, artist)\n",
    "        raw_lyrics = song.lyrics\n",
    "        lyrics, genres_and_release_date = raw_lyrics.split(John)\n",
    "        raw_genres, release_date = genres_and_release_date.split(flipped_John)\n",
    "        genres = raw_genres.split('_')\n",
    "                \n",
    "        if release_date == 'Unknown':\n",
    "            release_date = songInfo.date[val]\n",
    "        else:\n",
    "            release_date = convert_date(release_date)\n",
    "        sd = song.to_dict()\n",
    "        title = sd['title']\n",
    "\n",
    "        artists = process_artist_names(sd['artist_names'])\n",
    "        #songData.loc[val] = [release_date, artists, lyrics, genres, title]\n",
    "        print(f'Artists: {songInfo.artist[val]:>20}')\n",
    "        print(f'{\", \".join(artists):>29}')\n",
    "        print(f'Title: {songInfo.title[val][:20]:>32}')\n",
    "        print(f'{title[:20]:>39}')\n",
    "        print(f'Date: {songInfo.date[val]:>20}')\n",
    "        print(f'{release_date:>26}')\n",
    "        print(f'Genres: {\", \".join(genres):>20}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-richards",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = 18539\n",
    "song = genius.search_song('Woo-Hah!! Got you all in check')\n",
    "raw_lyrics = song.lyrics\n",
    "lyrics, genres_and_release_date = raw_lyrics.split(John)\n",
    "raw_genres, release_date = genres_and_release_date.split(flipped_John)\n",
    "genres = raw_genres.split('_')\n",
    "\n",
    "if release_date == 'Unknown':\n",
    "    release_date = songInfo.date[val]\n",
    "else:\n",
    "    release_date = convert_date(release_date)\n",
    "sd = song.to_dict()\n",
    "title = sd['title']\n",
    "\n",
    "artists = process_artist_names(sd['artist_names'])\n",
    "\n",
    "print(f'Artists: {songInfo.artist[val]:>20}')\n",
    "print(f'{\", \".join(artists):>29}')\n",
    "print(f'Title: {songInfo.title[val][:20]:>32}')\n",
    "print(f'{title[:20]:>39}')\n",
    "print(f'Date: {songInfo.date[val]:>20}')\n",
    "print(f'{release_date:>26}')\n",
    "print(f'Genres: {\", \".join(genres):>20}\\n')\n",
    "songData.loc[val] = [release_date, artists, lyrics, genres, title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-moment",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genres = set([])\n",
    "i = 0\n",
    "for genres in songData.genres:\n",
    "    i += 1\n",
    "    print(i, genres[2:-2])\n",
    "    genres = genres[2:-2].split(\"', '\")\n",
    "    for genre in genres:\n",
    "        all_genres.add(genre)\n",
    "all_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-chain",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect, detect_langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-genesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in song_data.index.values:\n",
    "    lyrics = \" \".join([token for token in set(nltk.tokenize.word_tokenize(song_data.lyrics[i])) if token.isalpha()])\n",
    "    if not lyrics:\n",
    "#         print(\"NO GUT HERE\")\n",
    "#         print(song_data.artists[i])\n",
    "#         print(song_data.title[i],\"\\n\")\n",
    "\n",
    "        song_data = song_data.drop(i)\n",
    "        continue\n",
    "    if langdetect.detect(lyrics) != \"en\":\n",
    "        print(i)\n",
    "#         print(song_data.artists[i])\n",
    "#         print(song_data.title[i])\n",
    "#         print(lyrics[:50],\"\\n\")\n",
    "        song_data = song_data.drop(i)\n",
    "#     print(langdetect.detect(lyrics))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-momentum",
   "metadata": {},
   "outputs": [],
   "source": [
    "songData.to_csv('songData_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romantic-video",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_songs = set()\n",
    "songs_count = {}\n",
    "\n",
    "for i, art, tit in zip(songData.index.values, songData.artists, songData.title):\n",
    "    song = ', '.join(art) + ': ' + tit\n",
    "    if song in all_songs:\n",
    "        songs_count[song] += 1\n",
    "        #songData = songData.drop(i)\n",
    "    else:\n",
    "        songs_count[song] = 1\n",
    "    all_songs.add(song)\n",
    "\n",
    "len(all_songs)\n",
    "\n",
    "songData.to_pickle('songData_noduplicates.df')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gross-victory",
   "metadata": {},
   "source": [
    "#### Removing long songs\n",
    "Afterwards, we made a decision to remove all songs where the lyrics were longer than 10,000 characters. This was done because, in spite of all the aforementioned approaches to clean the data, e.g. entire book chapters by the French novelist [Marcel Proust](https://en.wikipedia.org/wiki/Marcel_Proust) were still present in the dataset because they were labelled with the genre *rap*. The cut-off at 10,000 were chosen based on the fact that all songs we investigated that were longer, were songs that we clearly loaded in wrong. In addition to this, the 6-minute-long song *Rap God* by *Eminem*, where he flexes his ability to rap fast, contains 7,984 characters.\n",
    "\n",
    "While doing a finer combing of the data, we also produced a blacklist for artists that we deemed unwanted in the data set. This list includes *Glee Cast* as they were present in over 200 songs, even though their songs are covers of other popular songs. The full list is seen here `['highest to lowest', 'marcel proust', 'watsky', 'glee cast', 'harttsick', 'eric the red', 'fabvl', 'c-mob']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-botswana",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import langdetect\n",
    "import nltk.tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-prior",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_data = pd.read_pickle('songData_noduplicates.df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-addiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in song_data.index.values:\n",
    "    title = song_data.title[i]\n",
    "    song_data.lyrics[i] = \" \".join(song_data.lyrics[i].split(\"Lyrics\")[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-technique",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in song_data.index.values:\n",
    "    if \"\\u200e\" in song_data.lyrics[i]:\n",
    "        song_data.lyrics[i] = song_data.lyrics[i].replace('\\u200e', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-louis",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_list = [\"genius users cypher\", \"world record\"]\n",
    "for cut in cut_list:\n",
    "    for i in song_data.index.values:\n",
    "        if cut in song_data.title[i].lower():\n",
    "            song_data = song_data.drop(i)\n",
    "            print(i, cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-poster",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(lyrics) for lyrics in song_data.lyrics]\n",
    "# lengths = sorted(lengths, reverse=True)\n",
    "plt.hist(lengths, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-metallic",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(song_data[song_data.title == 'Rap God'].lyrics.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-stand",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_list = [\"highest to lowest\", \"marcel proust\", 'watsky', 'glee cast', 'harttsick', 'eric the red', 'fabvl', 'c-mob']\n",
    "for cut in cut_list:\n",
    "    for i in song_data.index.values:\n",
    "        if cut in song_data.artists[i]:\n",
    "            song_data = song_data.drop(i)\n",
    "            print(i, cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-watch",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in song_data.index.values:\n",
    "    if 'juice wrld' in song_data.artists[i]:\n",
    "        print(song_data.title[i])\n",
    "        print(len(song_data.lyrics[i]))\n",
    "        #song_data = song_data.drop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-august",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = -1 \n",
    "\n",
    "while True:\n",
    "    \n",
    "    lengths = [len(lyrics) for lyrics in song_data.lyrics]\n",
    "    a = np.argsort(lengths)[-1]\n",
    "    \n",
    "    index = song_data.index.values[a]\n",
    "    \n",
    "    if len(song_data.lyrics[index]) < 10_000:\n",
    "        break\n",
    "#     print(len(song_data.lyrics[index]))\n",
    "#     print(song_data.artists[index])\n",
    "#     print(song_data.title[index])\n",
    "#     print(song_data.lyrics[index])\n",
    "#     print(\"=\"*100)\n",
    "    song_data = song_data.drop(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(lyrics) for lyrics in song_data.lyrics]\n",
    "# lengths = sorted(lengths, reverse=True)\n",
    "plt.hist(lengths, bins = 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifteen-output",
   "metadata": {},
   "source": [
    "#### Regrouping artists\n",
    "\n",
    "As mentioned earlier, after gathering the data, we had to separate all artists to work with them properly, though in some cases, this results in one artist being split up into multiple - as was the case with *Earth, Wind & Fire*. To mitigate this problem, we first calculated how many times each artist appeared in the data set and afterwards, for each artist, how many times they apperead with collaborating artists. Having known these values, we could then for each artist check which other artists they have collaborated with on all of their songs. Artists found using this method were then joined with an underscore, such that `['earth', 'wind', 'fire']` became `['earth_fire_wind']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-penalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in song_data.index.values:\n",
    "    a = song_data.artists[i]\n",
    "    for j,artist in enumerate(a):\n",
    "        if ' (' in artist and ')' not in artist:\n",
    "            a.pop(j)\n",
    "            artist = artist.split(' (')[0].split(', ')\n",
    "            song_data.artists[i] = a + artist\n",
    "            print(artist)\n",
    "            print(song_data.title[i])\n",
    "            print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-share",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_count = defaultdict(lambda: 0)\n",
    "artist_colab_count = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "for artists in song_data.artists:\n",
    "    for artist in artists:\n",
    "        artist_count[artist] += 1\n",
    "        for colab in artists:\n",
    "            if colab != artist:\n",
    "                artist_colab_count[artist][colab] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-capability",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_artists = {k: v for k, v in sorted(artist_count.items(), key=lambda item: item[1], reverse=True) if v > 35}\n",
    "#for k, v in sorted_artists.items():\n",
    "#    print(k + ':', v)\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.bar(*zip(*sorted_artists.items()))\n",
    "plt.xlabel('Artist')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Count')\n",
    "plt.title('Songs pr. Artist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-swaziland",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_colab_count['wind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-detective",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_count['wind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-eleven",
   "metadata": {},
   "outputs": [],
   "source": [
    "regroupings = set()\n",
    "\n",
    "for artist_a, songs_a in artist_count.items():\n",
    "    colabs = [artist_a]\n",
    "    for artist_b, songs_b in artist_colab_count[artist_a].items():\n",
    "        if songs_b == artist_count[artist_b] == songs_a  and songs_a > 2:\n",
    "            colabs.append(artist_b)\n",
    "    if len(colabs) > 1:\n",
    "        regroupings.add((songs_a, tuple(sorted(colabs))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-recall",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in song_data.index.values:\n",
    "    for num, group in regroupings:\n",
    "        if group[0] in song_data.artists[i]:\n",
    "            print(f'Artists before: {song_data.artists[i]}')\n",
    "            for g in group:\n",
    "                song_data.artists[i].remove(g)\n",
    "            song_data.artists[i].append(\"_\".join(group))\n",
    "            print(f'Artists after: {song_data.artists[i]}')\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-rough",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_data.to_pickle(\"songData.df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-logging",
   "metadata": {},
   "source": [
    "### Preliminary look at the data\n",
    "After doing all data processing and cleaning, the final data set is comprised of 25,419 songs and 7,855 unique artists. In the table below, the three data sets used throughout the project can be seen and downloaded.\n",
    "\n",
    "| Data Set                                                                                             |  Songs | Size (mb) |\n",
    "|:-----------------------------------------------------------------------------------------------------|-------:|----------:|\n",
    "| [Billboard List](https://drive.google.com/file/d/1Gd4YH_U98Z8mellnIV_haINLL4UhLJKG/view?usp=sharing) | 29,128 |       1.6 |\n",
    "| [Pre-cleaned](https://drive.google.com/file/d/1cyiIWnXD_0CHLsj8C0tcwNadfYI7z8FD/view?usp=sharing)    | 29,128 |      92.5 |\n",
    "| [Cleaned](https://drive.google.com/file/d/1Zhof84KbTJa3a1zfhN3TcwdWqPFCTnEv/view?usp=sharing)        | 25,419 |      44.2 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-plymouth",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
